{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CreateModelsHeuristic.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":48,"metadata":{"id":"FU8Y-ahKZ0c7","colab":{"base_uri":"https://localhost:8080/","height":415},"executionInfo":{"status":"error","timestamp":1659014003761,"user_tz":-180,"elapsed":281,"user":{"displayName":"David Roskin","userId":"12568194440768580589"}},"outputId":"0d2cbc5f-58db-4658-ad93-6425c45465d3"},"outputs":[{"output_type":"error","ename":"TclError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-18897f0e78d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mplayer1_heuristic_player2_random_Combined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;31m# player1_heuristic_player2_random_weight()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# player1_heuristic_player2_minmax_Combined()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-48-18897f0e78d4>\u001b[0m in \u001b[0;36mplayer1_heuristic_player2_random_Combined\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplayer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepQLearnerAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_combined_heuristic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_OF_GAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"player0_heuristic_player1_random_Combined\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/MyDrive/final project AI/DeepQlearnerAgent.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, agent1, agent2, numGames, path)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mq_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mboards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mcurr_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCREATE_BOARD_TYPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mcurr_board\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/MyDrive/final project AI/CreateBoard.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mnew_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_player\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPLAYER_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;31m# self.root = Tk()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# self.gui = Canvas(self.root, width=500, height=600, background=\"#222\", highlightthickness=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2021\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"]}],"source":["#CreateModelsHeuristic\n","import matplotlib\n","matplotlib.use('Agg')\n","from tkinter import *  \n","def player1_heuristic_player2_random_Combined():\n","    player0 = HeuristicPlayer(None, weight_combined_heuristic, None, 0)\n","    player1 = RandomAgent(None, None, None, 1)\n","    model = DeepQLearnerAgent(None, weight_combined_heuristic, None, None)\n","    losses = model.train(player0, player1, NUM_OF_GAMES, \"player0_heuristic_player1_random_Combined\")\n","    plot_loss(losses)\n","\n","\n","def player1_heuristic_player2_random_weight():\n","    player0 = HeuristicPlayer(None, weight_place_heuristic, None, 0)\n","    player1 = RandomAgent(None, None, None, 1)\n","    model = DeepQLearnerAgent(None, weight_place_heuristic, None, None)\n","    losses = model.train(player0, player1, NUM_OF_GAMES, \"player0_heuristic_player1_random_weight\")\n","    plot_loss(losses)\n","\n","\n","\n","def player1_heuristic_player2_minmax_Combined():\n","    player0 = HeuristicPlayer(None, weight_combined_heuristic, None, 0)\n","    player1 = MinMaxAgent(None, weight_combined_heuristic, None, 1)\n","    model = DeepQLearnerAgent(None, weight_combined_heuristic, None, None)\n","    losses = model.train(player0, player1, NUM_OF_GAMES, \"player0_heuristic_player1_minmax_Combined\")\n","    plot_loss(losses)\n","\n","\n","\n","def player1_heuristic_player2_minmax_weight():\n","    player0 = HeuristicPlayer(None, weight_place_heuristic, None, 0)\n","    player1 = MinMaxAgent(None, weight_place_heuristic, None, 1)\n","    model = DeepQLearnerAgent(None, weight_place_heuristic, None, None)\n","    losses = model.train(player0, player1, NUM_OF_GAMES, \"player0_heuristic_player1_minmax_weight\")\n","    plot_loss(losses)\n","\n","\n","\n","def player1_heuristic_player2_heuristic_Combined():\n","    player0 = HeuristicPlayer(None, weight_combined_heuristic, None, 0)\n","    player1 = HeuristicPlayer(None, weight_combined_heuristic, None,1)\n","    model = DeepQLearnerAgent(None, weight_combined_heuristic, None, None)\n","    losses = model.train(player0, player1, NUM_OF_GAMES, \"player0_heuristic_player1_heuristic_Combined\")\n","    plot_loss(losses)\n","\n","\n","\n","def player1_heuristic_player2_heuristic_weight():\n","    player0 = HeuristicPlayer(None, weight_place_heuristic, None, 0)\n","    player1 = HeuristicPlayer(None, weight_place_heuristic, None, 1)\n","    model = DeepQLearnerAgent(None, weight_place_heuristic, None, None)\n","    losses = model.train(player0, player1, NUM_OF_GAMES, \"player0_heuristic_player1_heuristic_weight\")\n","    plot_loss(losses)\n","\n","\n","\n","if __name__ == '__main__':\n","    player1_heuristic_player2_random_Combined()\n","    # player1_heuristic_player2_random_weight()\n","    # player1_heuristic_player2_minmax_Combined()\n","    # player1_heuristic_player2_minmax_weight()\n","    # player1_heuristic_player2_heuristic_Combined()\n","    # player1_heuristic_player2_heuristic_weight()"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w_LZb6hzwZll","executionInfo":{"status":"ok","timestamp":1659014011671,"user_tz":-180,"elapsed":2293,"user":{"displayName":"David Roskin","userId":"12568194440768580589"}},"outputId":"e970cb96-cf7b-45be-a48b-80f4f8cd9815"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/gdrive/MyDrive/final project AI')"],"metadata":{"id":"YPnmJu3Vwak_","executionInfo":{"status":"ok","timestamp":1659014011672,"user_tz":-180,"elapsed":10,"user":{"displayName":"David Roskin","userId":"12568194440768580589"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["!pip install tkinter"],"metadata":{"id":"d1fDo74XkU_Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659013720268,"user_tz":-180,"elapsed":1011,"user":{"displayName":"David Roskin","userId":"12568194440768580589"}},"outputId":"cbfdc47b-df9e-496c-bb70-3f2b3f9a39ed"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement tkinter (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for tkinter\u001b[0m\n"]}]}]}